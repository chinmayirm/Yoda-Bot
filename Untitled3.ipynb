{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fcb4cbd4191e4fddb736be815d291281": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_da5e184ca024461594c755133007a663",
              "IPY_MODEL_d2f6ad1b262747d98e3ad2dd19b0d846",
              "IPY_MODEL_de65ac90f1f34b01817347195a27c86b"
            ],
            "layout": "IPY_MODEL_216fcc3ac3434d90b57451efc52ba33b"
          }
        },
        "da5e184ca024461594c755133007a663": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5f0e18a0a804f78a004629ff9fcc515",
            "placeholder": "​",
            "style": "IPY_MODEL_97daacf7211944fe86c65171203e3d0c",
            "value": "Map: 100%"
          }
        },
        "d2f6ad1b262747d98e3ad2dd19b0d846": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83058c2a013347b396a0c1fc6d7e9e2a",
            "max": 35,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f94e7914870a4717b1a03427699178c3",
            "value": 35
          }
        },
        "de65ac90f1f34b01817347195a27c86b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db4e0c6a8d1047448818a79fe8142c4f",
            "placeholder": "​",
            "style": "IPY_MODEL_04ddaa0b207e4bd1a0464e85721d636a",
            "value": " 35/35 [00:00&lt;00:00, 456.42 examples/s]"
          }
        },
        "216fcc3ac3434d90b57451efc52ba33b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5f0e18a0a804f78a004629ff9fcc515": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97daacf7211944fe86c65171203e3d0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83058c2a013347b396a0c1fc6d7e9e2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f94e7914870a4717b1a03427699178c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "db4e0c6a8d1047448818a79fe8142c4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04ddaa0b207e4bd1a0464e85721d636a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pxbs_hc7xfc",
        "outputId": "fac6c0ce-c99c-4e50-dd0a-bac1ea288a84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Collecting streamlit\n",
            "  Downloading streamlit-1.47.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.12-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m510.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.24.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.47.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.14)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.26.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.47.0-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.2.12-py3-none-any.whl (26 kB)\n",
            "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pyngrok, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 pyngrok-7.2.12 streamlit-1.47.0 watchdog-6.0.0\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (4.0.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.9.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.33.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.7.14)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Collecting streamlit-chat\n",
            "  Downloading streamlit_chat-0.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting streamlit-webrtc\n",
            "  Downloading streamlit_webrtc-0.63.3-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: streamlit>=0.63 in /usr/local/lib/python3.11/dist-packages (from streamlit-chat) (1.47.0)\n",
            "Collecting aioice>=0.10.1 (from streamlit-webrtc)\n",
            "  Downloading aioice-0.10.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting aiortc>=1.11.0 (from streamlit-webrtc)\n",
            "  Downloading aiortc-1.13.0-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from streamlit-webrtc) (25.0)\n",
            "Collecting dnspython>=2.0.0 (from aioice>=0.10.1->streamlit-webrtc)\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting ifaddr>=0.2.0 (from aioice>=0.10.1->streamlit-webrtc)\n",
            "  Downloading ifaddr-0.2.0-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting av<15.0.0,>=14.0.0 (from aiortc>=1.11.0->streamlit-webrtc)\n",
            "  Downloading av-14.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from aiortc>=1.11.0->streamlit-webrtc) (1.17.1)\n",
            "Collecting cryptography>=44.0.0 (from aiortc>=1.11.0->streamlit-webrtc)\n",
            "  Downloading cryptography-45.0.5-cp311-abi3-manylinux_2_34_x86_64.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: google-crc32c>=1.1 in /usr/local/lib/python3.11/dist-packages (from aiortc>=1.11.0->streamlit-webrtc) (1.7.1)\n",
            "Collecting pyee>=13.0.0 (from aiortc>=1.11.0->streamlit-webrtc)\n",
            "  Downloading pyee-13.0.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting pylibsrtp>=0.10.0 (from aiortc>=1.11.0->streamlit-webrtc)\n",
            "  Downloading pylibsrtp-0.12.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting pyopenssl>=25.0.0 (from aiortc>=1.11.0->streamlit-webrtc)\n",
            "  Downloading pyopenssl-25.1.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit>=0.63->streamlit-chat) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit>=0.63->streamlit-chat) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit>=0.63->streamlit-chat) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit>=0.63->streamlit-chat) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit>=0.63->streamlit-chat) (2.0.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit>=0.63->streamlit-chat) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit>=0.63->streamlit-chat) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit>=0.63->streamlit-chat) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit>=0.63->streamlit-chat) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit>=0.63->streamlit-chat) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit>=0.63->streamlit-chat) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit>=0.63->streamlit-chat) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit>=0.63->streamlit-chat) (4.14.1)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit>=0.63->streamlit-chat) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit>=0.63->streamlit-chat) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit>=0.63->streamlit-chat) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit>=0.63->streamlit-chat) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit-chat) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit-chat) (4.24.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit-chat) (1.47.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.0->aiortc>=1.11.0->streamlit-webrtc) (2.22)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=0.63->streamlit-chat) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit>=0.63->streamlit-chat) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit>=0.63->streamlit-chat) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit>=0.63->streamlit-chat) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-chat) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-chat) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-chat) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-chat) (2025.7.14)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=0.63->streamlit-chat) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit>=0.63->streamlit-chat) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit-chat) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit-chat) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit-chat) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit-chat) (0.26.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit>=0.63->streamlit-chat) (1.17.0)\n",
            "Downloading streamlit_chat-0.1.1-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading streamlit_webrtc-0.63.3-py3-none-any.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.8/216.8 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aioice-0.10.1-py3-none-any.whl (24 kB)\n",
            "Downloading aiortc-1.13.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading av-14.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.3/35.3 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cryptography-45.0.5-cp311-abi3-manylinux_2_34_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ifaddr-0.2.0-py3-none-any.whl (12 kB)\n",
            "Downloading pyee-13.0.0-py3-none-any.whl (15 kB)\n",
            "Downloading pylibsrtp-0.12.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyopenssl-25.1.0-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ifaddr, pyee, dnspython, av, pylibsrtp, cryptography, aioice, pyopenssl, aiortc, streamlit-webrtc, streamlit-chat\n",
            "  Attempting uninstall: cryptography\n",
            "    Found existing installation: cryptography 43.0.3\n",
            "    Uninstalling cryptography-43.0.3:\n",
            "      Successfully uninstalled cryptography-43.0.3\n",
            "  Attempting uninstall: pyopenssl\n",
            "    Found existing installation: pyOpenSSL 24.2.1\n",
            "    Uninstalling pyOpenSSL-24.2.1:\n",
            "      Successfully uninstalled pyOpenSSL-24.2.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 45.0.5 which is incompatible.\n",
            "pydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aioice-0.10.1 aiortc-1.13.0 av-14.4.0 cryptography-45.0.5 dnspython-2.7.0 ifaddr-0.2.0 pyee-13.0.0 pylibsrtp-0.12.0 pyopenssl-25.1.0 streamlit-chat-0.1.1 streamlit-webrtc-0.63.3\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.11/dist-packages (0.19.0)\n",
            "Requirement already satisfied: vaderSentiment in /usr/local/lib/python3.11/dist-packages (3.3.2)\n",
            "Requirement already satisfied: nltk>=3.9 in /usr/local/lib/python3.11/dist-packages (from textblob) (3.9.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from vaderSentiment) (2.32.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (2025.7.14)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.37.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.0)\n",
            "Requirement already satisfied: gradio-client==1.10.4 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.4)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.33.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.11.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.12.4)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.47.1)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.14.1)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.4->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.4->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "# set up and dependencies\n",
        "!pip install transformers torch streamlit pyngrok\n",
        "!pip install datasets accelerate\n",
        "!pip install streamlit-chat streamlit-webrtc\n",
        "!pip install textblob vaderSentiment\n",
        "!pip install gradio\n",
        "\n",
        "import torch\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorForLanguageModeling\n",
        ")\n",
        "from datasets import Dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import json\n",
        "import random\n",
        "from textblob import TextBlob\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "import streamlit as st\n",
        "import time\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Initialize sentiment analyzer\n",
        "sentiment_analyzer = SentimentIntensityAnalyzer()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# YODA SYNTAX TRANSFORMATION ENGINE\n",
        "\n",
        "class YodaSyntaxGenerator:\n",
        "    def __init__(self):\n",
        "        # common Yoda sentence patterns\n",
        "        self.yoda_phrases = [\n",
        "            \"Strong with the Force, {subject} {verb}\",\n",
        "            \"Much to learn, {subject} still {verb}\",\n",
        "            \"Patient you must be, {object}\",\n",
        "            \"In you, {emotion} I sense\",\n",
        "            \"Difficult to see. Always in motion is the future\",\n",
        "            \"Fear leads to suffering, {subject}\",\n",
        "            \"Powerful you have become, {subject}\",\n",
        "            \"Judge me by my size, do you?\",\n",
        "            \"When {time} years old you reach, look as good you will not\"\n",
        "        ]\n",
        "\n",
        "        self.yoda_connectors = [\n",
        "            \"Hmm.\", \"Yes.\", \"Mm-hmm.\", \"Much to learn.\", \"Strong in the Force.\",\n",
        "            \"Patience.\", \"Fear not.\", \"Trust your feelings.\", \"The Force is strong.\"\n",
        "        ]\n",
        "\n",
        "    def transform_to_yoda_syntax(self, text):\n",
        "        \"\"\"Transform regular English to Yoda-like syntax\"\"\"\n",
        "        # simple pattern matching for basic transformations\n",
        "        patterns = [\n",
        "            # \"You are X\" -> \"X, you are\"\n",
        "            (r\"You are (\\w+)\", r\"\\1, you are\"),\n",
        "            # \"I think X\" -> \"Think I, X\"\n",
        "            (r\"I think (.*)\", r\"Think I do, \\1\"),\n",
        "            # \"You should X\" -> \"X, you should\"\n",
        "            (r\"You should (.*)\", r\"\\1, you should\"),\n",
        "            # \"This is X\" -> \"X, this is\"\n",
        "            (r\"This is (.*)\", r\"\\1, this is\"),\n",
        "            # \"You can X\" -> \"X, you can\"\n",
        "            (r\"You can (.*)\", r\"\\1, you can\"),\n",
        "            # \"You will X\" -> \"X, you will\"\n",
        "            (r\"You will (.*)\", r\"\\1, you will\")\n",
        "        ]\n",
        "\n",
        "        transformed = text\n",
        "        for pattern, replacement in patterns:\n",
        "            transformed = re.sub(pattern, replacement, transformed, flags=re.IGNORECASE)\n",
        "\n",
        "        # Yoda-style prefixes/suffixes\n",
        "        yoda_starters = [\n",
        "            \"Hmm. \", \"Yes. \", \"Much to learn, you have. \", \"Strong with you, the Force is. \"\n",
        "        ]\n",
        "\n",
        "        yoda_enders = [\n",
        "            \", young one.\", \", you must.\", \", hmm.\", \", strong you are.\", \" Fear not.\"\n",
        "        ]\n",
        "\n",
        "        # randomly add Yoda elements\n",
        "        if random.random() < 0.3:\n",
        "            transformed = random.choice(yoda_starters) + transformed\n",
        "        if random.random() < 0.3:\n",
        "            transformed = transformed + random.choice(yoda_enders)\n",
        "\n",
        "        return transformed\n",
        "\n",
        "    def generate_yoda_question(self, topic):\n",
        "        \"\"\"Generate introspective questions in Yoda's style\"\"\"\n",
        "        questions = {\n",
        "            \"values\": [\n",
        "                \"Important to you, what values are?\",\n",
        "                \"Guide your decisions, what principles do?\",\n",
        "                \"Stand for, what do you?\",\n",
        "                \"In difficult times, to what do you turn?\"\n",
        "            ],\n",
        "            \"emotions\": [\n",
        "                \"Feel right now, how do you?\",\n",
        "                \"Your heart, what does it tell you?\",\n",
        "                \"Troubling you, what is?\",\n",
        "                \"Peace within yourself, found have you?\"\n",
        "            ],\n",
        "            \"goals\": [\n",
        "                \"Seek in life, what do you?\",\n",
        "                \"Your path, clear is it?\",\n",
        "                \"Accomplished, what wish you to have?\",\n",
        "                \"Drive you forward, what does?\"\n",
        "            ],\n",
        "            \"reflection\": [\n",
        "                \"Learned about yourself today, what have you?\",\n",
        "                \"Changed you, how has this experience?\",\n",
        "                \"Proud of, what are you?\",\n",
        "                \"Different tomorrow, what will you do?\"\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        return random.choice(questions.get(topic, questions[\"reflection\"]))\n",
        "\n",
        "# Initialize the Yoda syntax generator\n",
        "yoda_generator = YodaSyntaxGenerator()\n",
        "\n",
        "# Test\n",
        "test_sentences = [\n",
        "    \"You are very strong\",\n",
        "    \"I think you should meditate\",\n",
        "    \"You can find peace within yourself\",\n",
        "    \"This is your destiny\"\n",
        "]\n",
        "\n",
        "print(\"Testing Yoda Syntax Generator:\")\n",
        "for sentence in test_sentences:\n",
        "    transformed = yoda_generator.transform_to_yoda_syntax(sentence)\n",
        "    print(f\"Original: {sentence}\")\n",
        "    print(f\"Yoda: {transformed}\")\n",
        "    print(\"---\")"
      ],
      "metadata": {
        "id": "EXTxZZgL8HiI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92d94d2b-9deb-474b-a546-3c74ba1755a2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Yoda Syntax Generator:\n",
            "Original: You are very strong\n",
            "Yoda: very, you are strong\n",
            "---\n",
            "Original: I think you should meditate\n",
            "Yoda: Think I do, meditate, you should\n",
            "---\n",
            "Original: You can find peace within yourself\n",
            "Yoda: find peace within yourself, you can, young one.\n",
            "---\n",
            "Original: This is your destiny\n",
            "Yoda: your destiny, this is\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DATASET CREATION FOR YODA CHATBOT\n",
        "\n",
        "class YodaDatasetCreator:\n",
        "    def __init__(self):\n",
        "        self.datasets = {}\n",
        "\n",
        "    def create_yoda_quotes_dataset(self):\n",
        "        \"\"\"Dataset 1: Yoda quotes and wisdom\"\"\"\n",
        "        yoda_quotes = [\n",
        "            {\"input\": \"I'm feeling lost\", \"output\": \"Lost, feel you do? Hmm. In the Force, always find your way, you can. Trust your instincts, you must.\"},\n",
        "            {\"input\": \"I'm afraid\", \"output\": \"Fear leads to anger, anger leads to hate, hate leads to suffering. Face your fears, you must. Strong you are.\"},\n",
        "            {\"input\": \"I don't know what to do\", \"output\": \"Difficult to see. Always in motion is the future. But patient you must be. In time, clear your path will become.\"},\n",
        "            {\"input\": \"I feel angry\", \"output\": \"Anger, to the dark side it leads. Breathe, you must. Let go of your anger. Peace, find you will.\"},\n",
        "            {\"input\": \"I'm not strong enough\", \"output\": \"Judge me by my size, do you? Strong in the Force you are. Believe in yourself, you must.\"},\n",
        "            {\"input\": \"I want to give up\", \"output\": \"Give up, a Jedi never does. Try not. Do, or do not. There is no try. Continue, you must.\"},\n",
        "            {\"input\": \"How do I find peace?\", \"output\": \"Peace, from within it comes. Quiet your mind. Feel the Force flow through you. Meditate, you should.\"},\n",
        "            {\"input\": \"What is my purpose?\", \"output\": \"Your purpose, reveal itself it will. Serve others, a Jedi's path it is. Listen to the Force, you must.\"},\n",
        "            {\"input\": \"I feel overwhelmed\", \"output\": \"Overwhelmed, feel you do? Focus on the present moment. One step at a time, take you must. Clear your mind of questions.\"},\n",
        "            {\"input\": \"I made a mistake\", \"output\": \"Mistakes, the greatest teacher they are. Learn from them, you must. Perfect, no one is. Grow stronger, failures make you.\"},\n",
        "            {\"input\": \"I don't believe in myself\", \"output\": \"Believe in yourself, essential it is. The Force, it surrounds us, binds us. Trust in your abilities, you must.\"},\n",
        "            {\"input\": \"How do I handle difficult people?\", \"output\": \"Patience, with difficult people you need. Compassion, show them you must. Their pain, understand you should.\"},\n",
        "            {\"input\": \"What are my values?\", \"output\": \"Important to you, what values are? Deep within, look you must. Guide your actions, they should. Reflect, you must.\"},\n",
        "            {\"input\": \"How do I make decisions?\", \"output\": \"Decisions, trust your feelings you must. The Force, guide you it will. Quiet your mind, clear your thoughts. Listen within.\"},\n",
        "            {\"input\": \"I feel sad\", \"output\": \"Sadness, natural it is. Through you, let it flow. Attached to your emotions, become not. Pass, this feeling will.\"}\n",
        "        ]\n",
        "        return yoda_quotes\n",
        "\n",
        "    def create_introspective_dataset(self):\n",
        "        \"\"\"Dataset 2: Introspective guidance in Yoda's style\"\"\"\n",
        "        introspective_data = [\n",
        "            {\"input\": \"Tell me about my personality\", \"output\": \"Your personality, know it you must. Reflect on your actions, you should. What drives you? What fears you? Within, the answers lie.\"},\n",
        "            {\"input\": \"What are my strengths?\", \"output\": \"Strong you are, in ways yet unknown. Your compassion, feel it I do. Your determination, see it I can. Recognize them yourself, you must.\"},\n",
        "            {\"input\": \"What are my weaknesses?\", \"output\": \"Weaknesses, acknowledge them you must. Growth, they offer. Impatience, anger, fear - common they are. Face them, stronger you become.\"},\n",
        "            {\"input\": \"How do I improve myself?\", \"output\": \"Improve yourself, daily practice requires. Meditate, you must. Learn from others, humble you should be. Patient with yourself, be.\"},\n",
        "            {\"input\": \"What habits should I change?\", \"output\": \"Your habits, examine you must. Serve you well, do they? If not, change them you should. Difficult but necessary, this path is.\"},\n",
        "            {\"input\": \"How do I find my life purpose?\", \"output\": \"Your purpose, already within you it exists. Listen to your heart, you must. What brings you joy? What helps others? There, your path lies.\"},\n",
        "            {\"input\": \"What motivates me?\", \"output\": \"Motivation, from within it comes. What makes your spirit soar? What challenges excite you? Deep within, look you must.\"},\n",
        "            {\"input\": \"How do I handle stress?\", \"output\": \"Stress, the enemy of clear thinking it is. Breathe deeply, you must. Present moment, focus on. Let go of what control you cannot.\"},\n",
        "            {\"input\": \"What makes me happy?\", \"output\": \"Happiness, choose you must. In simple moments, find it you can. Gratitude, the path to joy it is. What brings you peace? Remember, you should.\"},\n",
        "            {\"input\": \"How do I build confidence?\", \"output\": \"Confidence, from self-knowledge comes. Your accomplishments, remember them. Your growth, celebrate it. Worthy you are, believe this you must.\"}\n",
        "        ]\n",
        "        return introspective_data\n",
        "\n",
        "    def create_emotional_support_dataset(self):\n",
        "        \"\"\"Dataset 3: Emotional support and guidance\"\"\"\n",
        "        emotional_data = [\n",
        "            {\"input\": \"I feel lonely\", \"output\": \"Alone, truly you are not. Connected to all living things, you are. The Force, binds us together. Reach out, you must.\"},\n",
        "            {\"input\": \"I'm worried about the future\", \"output\": \"The future, always in motion it is. Control it, you cannot. Focus on now, you must. Present moment, your power lies in.\"},\n",
        "            {\"input\": \"I feel stuck\", \"output\": \"Stuck, feel you do? Move forward, sometimes backward you must go. New perspective, seek you should. Change your approach, necessary it may be.\"},\n",
        "            {\"input\": \"I don't feel good enough\", \"output\": \"Good enough, already you are. Perfect, no one needs to be. Your worth, not in achievements it lies. Valuable, your existence is.\"},\n",
        "            {\"input\": \"I'm dealing with loss\", \"output\": \"Loss, part of life it is. Grieve, you must. But attached to what was, become not. Live on in memories, they do. Heal, time will help you.\"},\n",
        "            {\"input\": \"I feel guilty\", \"output\": \"Guilt, heavy burden it is. Forgive yourself, you must. Learn from your actions, but punish yourself, do not. Move forward, you can.\"},\n",
        "            {\"input\": \"I'm struggling with relationships\", \"output\": \"Relationships, work they require. Listen more, speak less. Understand others, seek to. Patience and compassion, your tools they are.\"},\n",
        "            {\"input\": \"I feel anxious\", \"output\": \"Anxiety, fear of unknown it is. Breathe, you must. Present moment, return to. Control what you can, let go of what you cannot.\"},\n",
        "            {\"input\": \"I'm having trouble sleeping\", \"output\": \"Rest, your body needs. Quiet your mind, you must. Worries of the day, release them. Peace, in stillness find you will.\"},\n",
        "            {\"input\": \"I feel overwhelmed by choices\", \"output\": \"Many paths, see you do. Choose you must, but perfect choice, not needed. Trust the Force, guide you it will. Forward, any step is progress.\"}\n",
        "        ]\n",
        "        return emotional_data\n",
        "\n",
        "    def combine_datasets(self):\n",
        "        \"\"\"Combine all datasets into training format\"\"\"\n",
        "        all_data = []\n",
        "        all_data.extend(self.create_yoda_quotes_dataset())\n",
        "        all_data.extend(self.create_introspective_dataset())\n",
        "        all_data.extend(self.create_emotional_support_dataset())\n",
        "\n",
        "       #formatting\n",
        "        formatted_data = []\n",
        "        for item in all_data:\n",
        "            formatted_data.append({\n",
        "                \"text\": f\"Human: {item['input']}\\nYoda: {item['output']}\"\n",
        "            })\n",
        "\n",
        "        return formatted_data\n",
        "\n",
        "    def save_dataset(self, filename=\"yoda_training_data.json\"):\n",
        "        \"\"\"Save dataset to file\"\"\"\n",
        "        data = self.combine_datasets()\n",
        "        with open(filename, 'w') as f:\n",
        "            json.dump(data, f, indent=2)\n",
        "        print(f\"Dataset saved to {filename}\")\n",
        "        print(f\"Total examples: {len(data)}\")\n",
        "        return data\n",
        "\n",
        "dataset_creator = YodaDatasetCreator()\n",
        "training_data = dataset_creator.save_dataset()\n",
        "\n",
        "print(\"\\nSample training examples:\")\n",
        "for i, example in enumerate(training_data[:3]):\n",
        "    print(f\"Example {i+1}:\")\n",
        "    print(example['text'])\n",
        "    print(\"---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkpdEcEe8iqt",
        "outputId": "046eb8a7-2c1d-4e84-ce7d-92250b09c270"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset saved to yoda_training_data.json\n",
            "Total examples: 35\n",
            "\n",
            "Sample training examples:\n",
            "Example 1:\n",
            "Human: I'm feeling lost\n",
            "Yoda: Lost, feel you do? Hmm. In the Force, always find your way, you can. Trust your instincts, you must.\n",
            "---\n",
            "Example 2:\n",
            "Human: I'm afraid\n",
            "Yoda: Fear leads to anger, anger leads to hate, hate leads to suffering. Face your fears, you must. Strong you are.\n",
            "---\n",
            "Example 3:\n",
            "Human: I don't know what to do\n",
            "Yoda: Difficult to see. Always in motion is the future. But patient you must be. In time, clear your path will become.\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade transformers --quiet\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VuS7E8s_0Iq",
        "outputId": "2fb534a6-c98e-435f-ac45-8ae769e1a876"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m816.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MODEL TRAINING & FINE-TUNING\n",
        "\n",
        "class YodaChatbotTrainer:\n",
        "    def __init__(self, model_name=\"microsoft/DialoGPT-small\"):\n",
        "        self.model_name = model_name\n",
        "        self.tokenizer = None\n",
        "        self.model = None\n",
        "\n",
        "    def load_model_and_tokenizer(self):\n",
        "        \"\"\"Load pre-trained model and tokenizer\"\"\"\n",
        "        print(f\"Loading model: {self.model_name}\")\n",
        "\n",
        "\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
        "\n",
        "\n",
        "        special_tokens = {\n",
        "            \"pad_token\": \"<pad>\",\n",
        "            \"eos_token\": \"</s>\",\n",
        "            \"bos_token\": \"<s>\",\n",
        "        }\n",
        "\n",
        "        # Add tokens that don't exist\n",
        "        new_tokens = []\n",
        "        for key, token in special_tokens.items():\n",
        "            if getattr(self.tokenizer, key) is None:\n",
        "                new_tokens.append(token)\n",
        "                setattr(self.tokenizer, key, token)\n",
        "\n",
        "\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(self.model_name)\n",
        "\n",
        "        # Resize token embeddings if new tokens were added\n",
        "        if new_tokens:\n",
        "            self.tokenizer.add_special_tokens({\"additional_special_tokens\": new_tokens})\n",
        "            self.model.resize_token_embeddings(len(self.tokenizer))\n",
        "\n",
        "\n",
        "        self.model.to(device)\n",
        "\n",
        "        print(\"Model and tokenizer loaded successfully!\")\n",
        "\n",
        "    def prepare_dataset(self, training_data):\n",
        "        \"\"\"Prepare dataset for training\"\"\"\n",
        "        def tokenize_function(examples):\n",
        "            # Tokenize the text\n",
        "            tokenized = self.tokenizer(\n",
        "                examples['text'],\n",
        "                truncation=True,\n",
        "                padding=True,\n",
        "                max_length=512,\n",
        "                return_tensors=\"pt\"\n",
        "            )\n",
        "            # For causal LM, labels are the same as input_ids\n",
        "            tokenized[\"labels\"] = tokenized[\"input_ids\"].clone()\n",
        "            return tokenized\n",
        "\n",
        "\n",
        "        dataset = Dataset.from_list(training_data)\n",
        "\n",
        "\n",
        "        tokenized_dataset = dataset.map(\n",
        "            tokenize_function,\n",
        "            batched=True,\n",
        "            remove_columns=dataset.column_names\n",
        "        )\n",
        "\n",
        "        return tokenized_dataset\n",
        "\n",
        "    def train_model(self, training_data, output_dir=\"./yoda-chatbot\"):\n",
        "        \"\"\"Train the model\"\"\"\n",
        "        print(\"Preparing dataset...\")\n",
        "        tokenized_dataset = self.prepare_dataset(training_data)\n",
        "\n",
        "        # Data collator\n",
        "        data_collator = DataCollatorForLanguageModeling(\n",
        "            tokenizer=self.tokenizer,\n",
        "            mlm=False,  # as we're not doing masked language modeling\n",
        "        )\n",
        "\n",
        "        # training args\n",
        "        training_args = TrainingArguments(\n",
        "            output_dir=output_dir,\n",
        "            overwrite_output_dir=True,\n",
        "            num_train_epochs=3,\n",
        "            per_device_train_batch_size=4,\n",
        "            per_device_eval_batch_size=4,\n",
        "            warmup_steps=100,\n",
        "            logging_steps=50,\n",
        "            save_steps=500,\n",
        "            #evaluation_strategy=\"epoch\",\n",
        "            save_strategy=\"epoch\",\n",
        "            load_best_model_at_end=False,\n",
        "            dataloader_num_workers=0,\n",
        "            fp16=torch.cuda.is_available(),\n",
        "        )\n",
        "\n",
        "\n",
        "        trainer = Trainer(\n",
        "            model=self.model,\n",
        "            args=training_args,\n",
        "            data_collator=data_collator,\n",
        "            train_dataset=tokenized_dataset,\n",
        "            tokenizer=self.tokenizer,\n",
        "        )\n",
        "\n",
        "        print(\"Starting training...\")\n",
        "        trainer.train()\n",
        "\n",
        "\n",
        "        trainer.save_model(output_dir)\n",
        "        self.tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "        print(f\"Model trained and saved to {output_dir}\")\n",
        "\n",
        "    def load_trained_model(self, model_path=\"./yoda-chatbot\"):\n",
        "        \"\"\"Load the trained model\"\"\"\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(model_path)\n",
        "        self.model.to(device)\n",
        "        print(\"Trained model loaded successfully!\")\n",
        "\n",
        "\n",
        "trainer = YodaChatbotTrainer()\n",
        "\n",
        "trainer.load_model_and_tokenizer()\n",
        "\n",
        "\n",
        "print(\"Starting model training...\")\n",
        "trainer.train_model(training_data)\n",
        "print(\"done\")\n"
      ],
      "metadata": {
        "id": "7EJJL5dm8rPq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576,
          "referenced_widgets": [
            "fcb4cbd4191e4fddb736be815d291281",
            "da5e184ca024461594c755133007a663",
            "d2f6ad1b262747d98e3ad2dd19b0d846",
            "de65ac90f1f34b01817347195a27c86b",
            "216fcc3ac3434d90b57451efc52ba33b",
            "c5f0e18a0a804f78a004629ff9fcc515",
            "97daacf7211944fe86c65171203e3d0c",
            "83058c2a013347b396a0c1fc6d7e9e2a",
            "f94e7914870a4717b1a03427699178c3",
            "db4e0c6a8d1047448818a79fe8142c4f",
            "04ddaa0b207e4bd1a0464e85721d636a"
          ]
        },
        "outputId": "ea690aa9-5c7d-4a32-f8c0-9ff8306baa3d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model: microsoft/DialoGPT-small\n",
            "Model and tokenizer loaded successfully!\n",
            "Starting model training...\n",
            "Preparing dataset...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/35 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fcb4cbd4191e4fddb736be815d291281"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-17-3386070380.py:99: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchinmayi5405\u001b[0m (\u001b[33mchinmayi5405-\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250722_164526-cpkv1t2b</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/chinmayi5405-/huggingface/runs/cpkv1t2b' target=\"_blank\">./yoda-chatbot</a></strong> to <a href='https://wandb.ai/chinmayi5405-/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/chinmayi5405-/huggingface' target=\"_blank\">https://wandb.ai/chinmayi5405-/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/chinmayi5405-/huggingface/runs/cpkv1t2b' target=\"_blank\">https://wandb.ai/chinmayi5405-/huggingface/runs/cpkv1t2b</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [27/27 04:04, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained and saved to ./yoda-chatbot\n",
            "done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# EMOTIONAL TONE DETECTION SYSTEM\n",
        "\n",
        "class EmotionDetector:\n",
        "    def __init__(self):\n",
        "        self.sentiment_analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "\n",
        "        self.emotion_keywords = {\n",
        "            'sad': ['sad', 'depressed', 'down', 'blue', 'melancholy', 'gloomy', 'heartbroken', 'grief'],\n",
        "            'angry': ['angry', 'furious', 'mad', 'irritated', 'rage', 'frustrated', 'annoyed'],\n",
        "            'anxious': ['anxious', 'worried', 'nervous', 'stressed', 'panic', 'fear', 'scared'],\n",
        "            'happy': ['happy', 'joy', 'excited', 'cheerful', 'glad', 'pleased', 'delighted'],\n",
        "            'confused': ['confused', 'lost', 'uncertain', 'unclear', 'puzzled', 'bewildered'],\n",
        "            'lonely': ['lonely', 'alone', 'isolated', 'abandoned', 'friendless'],\n",
        "            'guilty': ['guilty', 'ashamed', 'regret', 'remorse', 'blame'],\n",
        "            'hopeful': ['hopeful', 'optimistic', 'confident', 'positive', 'encouraged'],\n",
        "            'overwhelmed': ['overwhelmed', 'stressed', 'burden', 'too much', 'exhausted']\n",
        "        }\n",
        "\n",
        "    def detect_emotion(self, text):\n",
        "        \"\"\"Detect primary emotion in text\"\"\"\n",
        "        text_lower = text.lower()\n",
        "\n",
        "\n",
        "        detected_emotions = []\n",
        "        for emotion, keywords in self.emotion_keywords.items():\n",
        "            for keyword in keywords:\n",
        "                if keyword in text_lower:\n",
        "                    detected_emotions.append(emotion)\n",
        "                    break\n",
        "\n",
        "\n",
        "        sentiment_scores = self.sentiment_analyzer.polarity_scores(text)\n",
        "\n",
        "\n",
        "        if detected_emotions:\n",
        "            primary_emotion = detected_emotions[0]  # Take first detected emotion\n",
        "        else:\n",
        "            # Fall back to sentiment analysis\n",
        "            compound_score = sentiment_scores['compound']\n",
        "            if compound_score >= 0.1:\n",
        "                primary_emotion = 'positive'\n",
        "            elif compound_score <= -0.1:\n",
        "                primary_emotion = 'negative'\n",
        "            else:\n",
        "                primary_emotion = 'neutral'\n",
        "\n",
        "        return {\n",
        "            'primary_emotion': primary_emotion,\n",
        "            'detected_emotions': detected_emotions,\n",
        "            'sentiment_scores': sentiment_scores,\n",
        "            'intensity': abs(sentiment_scores['compound'])\n",
        "        }\n",
        "\n",
        "    def get_yoda_response_for_emotion(self, emotion, intensity):\n",
        "        \"\"\"Get appropriate Yoda response based on emotion\"\"\"\n",
        "        responses = {\n",
        "            'sad': {\n",
        "                'high': \"Deep sadness, feel in you I do. Through this darkness, guide you I will. Pass, all feelings do. Stronger, you will emerge.\",\n",
        "                'medium': \"Sad you are, sense it I can. Normal this is. Feel your emotions, you must, but consumed by them, be not.\",\n",
        "                'low': \"A shadow of sadness, detect I do. Acknowledge it, you should. Lift in time, your spirits will.\"\n",
        "            },\n",
        "            'angry': {\n",
        "                'high': \"Great anger, feel in you I do. Dangerous it is. Control your anger, you must, or control you, it will.\",\n",
        "                'medium': \"Anger, clouds your judgment it does. Breathe deeply. Let go of this anger, you must.\",\n",
        "                'low': \"Irritation, sense I do. Patience, practice you must. Pass, this feeling will.\"\n",
        "            },\n",
        "            'anxious': {\n",
        "                'high': \"Much fear and anxiety, overwhelming you it is. Present moment, focus on. Breathe, you must.\",\n",
        "                'medium': \"Worried you are, feel it I can. Control the future, you cannot. Peace in acceptance, find you will.\",\n",
        "                'low': \"Slight worry, detect I do. Natural this is. Trust in yourself, you must.\"\n",
        "            },\n",
        "            'happy': {\n",
        "                'high': \"Great joy, radiate from you it does! Wonderful this is. Share your happiness, you should.\",\n",
        "                'medium': \"Happy you are, sense this I do. Good, this feeling is. Grateful, be you should.\",\n",
        "                'low': \"Content you seem. Peaceful, your energy is. Nurture this feeling, you must.\"\n",
        "            },\n",
        "            'confused': {\n",
        "                'high': \"Lost you are, feel this strongly I do. Clear your mind, you must. Patience, answers will come.\",\n",
        "                'medium': \"Uncertain you feel. Normal this is. In confusion, opportunity for growth lies.\",\n",
        "                'low': \"Slightly puzzled, sense in you I do. Clarity, comes with reflection it does.\"\n",
        "            },\n",
        "            'lonely': {\n",
        "                'high': \"Deep loneliness, heavy in your heart it weighs. Connected to all living things, you are. Alone, truly you are not.\",\n",
        "                'medium': \"Lonely you feel. Reach out, you must. Others, need connection they do too.\",\n",
        "                'low': \"Solitude, sometimes necessary it is. But isolated, forever remain you should not.\"\n",
        "            },\n",
        "            'guilty': {\n",
        "                'high': \"Heavy guilt, burden you it does. Forgive yourself, you must. Learn and grow, the path forward it is.\",\n",
        "                'medium': \"Regret, feel in you I do. Mistakes, teachers they are. Move forward, you can.\",\n",
        "                'low': \"Some remorse, natural it is. Acknowledge it, then release it, you must.\"\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Determine intensity level\n",
        "        if intensity > 0.6:\n",
        "            intensity_level = 'high'\n",
        "        elif intensity > 0.3:\n",
        "            intensity_level = 'medium'\n",
        "        else:\n",
        "            intensity_level = 'low'\n",
        "\n",
        "        # Get response for emotion and intensity\n",
        "        emotion_responses = responses.get(emotion, {})\n",
        "        response = emotion_responses.get(intensity_level, \"Sense your feelings, I do. Guide you, I will.\")\n",
        "\n",
        "        return response\n",
        "\n",
        "\n",
        "emotion_detector = EmotionDetector()\n",
        "\n",
        "\n",
        "test_messages = [\n",
        "    \"I'm feeling really sad today\",\n",
        "    \"I'm so angry about what happened\",\n",
        "    \"I'm worried about my future\",\n",
        "    \"I'm happy and excited!\",\n",
        "    \"I don't know what to do, I'm so confused\"\n",
        "]\n",
        "\n",
        "print(\"Testing Emotion Detection:\")\n",
        "for message in test_messages:\n",
        "    emotion_data = emotion_detector.detect_emotion(message)\n",
        "    response = emotion_detector.get_yoda_response_for_emotion(\n",
        "        emotion_data['primary_emotion'],\n",
        "        emotion_data['intensity']\n",
        "    )\n",
        "    print(f\"Input: {message}\")\n",
        "    print(f\"Emotion: {emotion_data['primary_emotion']} (Intensity: {emotion_data['intensity']:.2f})\")\n",
        "    print(f\"Yoda Response: {response}\")\n",
        "    print(\"---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UtxYw6h-82t",
        "outputId": "7b065d15-7e02-4794-8d4c-95adb170429a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Emotion Detection:\n",
            "Input: I'm feeling really sad today\n",
            "Emotion: sad (Intensity: 0.44)\n",
            "Yoda Response: Sad you are, sense it I can. Normal this is. Feel your emotions, you must, but consumed by them, be not.\n",
            "---\n",
            "Input: I'm so angry about what happened\n",
            "Emotion: angry (Intensity: 0.56)\n",
            "Yoda Response: Anger, clouds your judgment it does. Breathe deeply. Let go of this anger, you must.\n",
            "---\n",
            "Input: I'm worried about my future\n",
            "Emotion: anxious (Intensity: 0.30)\n",
            "Yoda Response: Slight worry, detect I do. Natural this is. Trust in yourself, you must.\n",
            "---\n",
            "Input: I'm happy and excited!\n",
            "Emotion: happy (Intensity: 0.75)\n",
            "Yoda Response: Great joy, radiate from you it does! Wonderful this is. Share your happiness, you should.\n",
            "---\n",
            "Input: I don't know what to do, I'm so confused\n",
            "Emotion: confused (Intensity: 0.46)\n",
            "Yoda Response: Uncertain you feel. Normal this is. In confusion, opportunity for growth lies.\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import random\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class YodaChatbot:\n",
        "    def __init__(self, model_path=\"./yoda-chatbot\"):\n",
        "        self.yoda_generator = YodaSyntaxGenerator()\n",
        "        self.emotion_detector = EmotionDetector()\n",
        "        self.trainer = YodaChatbotTrainer()\n",
        "        self.conversation_history = []\n",
        "        self.session_insights = []\n",
        "\n",
        "        self.question_categories = ['values', 'emotions', 'goals', 'reflection']\n",
        "        self.current_category_index = 0\n",
        "\n",
        "        # Load trained model or fallback to base model\n",
        "        try:\n",
        "            self.trainer.load_trained_model(model_path)\n",
        "            self.model_loaded = True\n",
        "        except:\n",
        "            print(\"Trained model not found. Loading base model...\")\n",
        "            self.trainer.load_model_and_tokenizer()\n",
        "            self.model_loaded = False\n",
        "\n",
        "    def generate_response(self, user_input):\n",
        "        emotion_data = self.emotion_detector.detect_emotion(user_input)\n",
        "\n",
        "        if emotion_data['intensity'] > 0.4:\n",
        "            response = self.emotion_detector.get_yoda_response_for_emotion(\n",
        "                emotion_data['primary_emotion'],\n",
        "                emotion_data['intensity']\n",
        "            )\n",
        "        else:\n",
        "            if self.model_loaded:\n",
        "                response = self._generate_model_response(user_input)\n",
        "            else:\n",
        "                response = self._generate_rule_based_response(user_input)\n",
        "\n",
        "        if not self._is_already_yoda_style(response):\n",
        "            response = self.yoda_generator.transform_to_yoda_syntax(response)\n",
        "\n",
        "        self.conversation_history.append({\n",
        "            'user': user_input,\n",
        "            'yoda': response,\n",
        "            'emotion': emotion_data\n",
        "        })\n",
        "\n",
        "        return response, emotion_data\n",
        "\n",
        "    def _generate_model_response(self, user_input):\n",
        "        prompt = f\"Human: {user_input}\\nYoda:\"\n",
        "        inputs = self.trainer.tokenizer.encode(prompt, return_tensors='pt').to(device)\n",
        "\n",
        "        outputs = self.trainer.model.generate(\n",
        "            inputs,\n",
        "            max_length=150,\n",
        "            pad_token_id=self.trainer.tokenizer.eos_token_id,\n",
        "            do_sample=True,\n",
        "            top_k=50,\n",
        "            top_p=0.95,\n",
        "            temperature=0.8,\n",
        "        )\n",
        "\n",
        "        decoded = self.trainer.tokenizer.decode(outputs[:, inputs.shape[-1]:][0], skip_special_tokens=True)\n",
        "        return decoded.strip()\n",
        "\n",
        "    def _generate_rule_based_response(self, user_input):\n",
        "        # Basic fallback response\n",
        "        templates = [\n",
        "            \"Much to learn, you still have.\",\n",
        "            \"Hmm. The Force, strong it is in you.\",\n",
        "            \"Answer you, I will. But first, patience you must have.\",\n",
        "            \"Clarity, in your mind you must seek.\"\n",
        "        ]\n",
        "        return random.choice(templates)\n",
        "\n",
        "    def _is_already_yoda_style(self, response):\n",
        "        return \"hmm\" in response.lower() or \"you must\" in response.lower()\n"
      ],
      "metadata": {
        "id": "OgR5S0n7CnBg"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "# Initialize your chatbot instance\n",
        "chatbot = YodaChatbot()\n",
        "\n",
        "def chat_with_yoda(user_input):\n",
        "    response, emotion_data = chatbot.generate_response(user_input)\n",
        "    return response\n",
        "\n",
        "gr.Interface(\n",
        "    fn=chat_with_yoda,\n",
        "    inputs=gr.Textbox(label=\"Enter your message to Yoda\"),\n",
        "    outputs=gr.Textbox(label=\"Yoda's Response\"),\n",
        "    title=\"Yoda Chatbot\",\n",
        "    description=\"Ask Yoda anything. Emotions and wisdom, he brings.\"\n",
        ").launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "id": "Fow00JZbDhTM",
        "outputId": "5dcba23a-cb29-49fc-c70c-032de94a6b5f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trained model loaded successfully!\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://c6e35fdc74909b98f6.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://c6e35fdc74909b98f6.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_yiJlKfBEUks"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}